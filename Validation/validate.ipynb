{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Validation Suite**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose and Setup\n",
    "This notebook will allow you to test the output from WRF-GHG against surface, upper air, and satelite observations.\n",
    "\n",
    "The next cell imports modules needed to work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wrf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from netCDF4 import Dataset as Ds #type: ignore\n",
    "from termcolor import cprint\n",
    "import pytz\n",
    "from numpy import unravel_index\n",
    "import collections.abc as c\n",
    "import numpy.typing as npt\n",
    "import metpy as mp\n",
    "from metpy.units import units\n",
    "from metpy.calc import wind_components\n",
    "from xarray import DataArray, Dataset\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from enum import IntFlag, auto\n",
    "import matplotlib.pyplot as plt\n",
    "units.define('ppb = 1e-9')\n",
    "units.define('@alias ppm = ppmv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Bit-flags for Validation failure*\n",
    "\n",
    "This class is used for setting a bit-flag to comunicate which variable didn't validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bitflag(IntFlag):\n",
    "    PRES = auto()\n",
    "    TEMP = auto()\n",
    "    DEWP = auto()\n",
    "    U = auto()\n",
    "    V = auto()\n",
    "    T2 = auto()\n",
    "    TD2 = auto()\n",
    "    SLP = auto()\n",
    "    U10 = auto()\n",
    "    V10 = auto()\n",
    "    XCO2 = auto()\n",
    "    XCO = auto()\n",
    "    XCH4 = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Base class*\n",
    "\n",
    "This class is used for all the following classes in order to give some basic location data to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_point:\n",
    "    '''\n",
    "    Base_point: parent class for validation. Sets location name.\n",
    "    '''\n",
    "    def __init__(self, loc: str, **kwargs) -> None:\n",
    "        self.loc: str = loc\n",
    "    @staticmethod\n",
    "    def _rmse(x:npt.ArrayLike, y:npt.ArrayLike) -> float:\n",
    "        error = x - y\n",
    "        sqr_error = error**2\n",
    "        mse = np.mean(sqr_error)\n",
    "        rmse = mse**(1/2)\n",
    "        return rmse\n",
    "    @staticmethod\n",
    "    def _mean_bias(x:npt.ArrayLike, y:npt.ArrayLike) -> float:\n",
    "        return np.mean(x - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Upper air (UA) class*\n",
    "\n",
    "This class is used to set the attributes for any data objects that cares about upper air data. This is usually the WRF data that you're testing or the radiosonde data you use for validation. It inherits from the base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UA_point(Base_point):\n",
    "    def __init__(self, loc: str, **kwargs) -> None:\n",
    "        super().__init__(loc, **kwargs)\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        try:\n",
    "            results: npt.NDArray[np.bool_] = np.empty(5, np.bool_)\n",
    "            results[0] = self._rmse(self.p, other.p) #! add validation limit here\n",
    "            results[1] = self._rmse(self.t, other.t) #! add validation limit here\n",
    "            results[2] = self._rmse(self.td, other.td) #! add validation limit here\n",
    "            results[3] = self._rmse(self.wdir, other.wdir) #! add validation limit here\n",
    "            results[4] = self._rmse(self.wspd, other.wspd) #! add validation limit here\n",
    "            result: bool = bool(results.all())\n",
    "        except AttributeError:\n",
    "            if isinstance(self, WRF_point):\n",
    "                result: bool = other.__eq__(self)\n",
    "            else:\n",
    "                raise NotImplementedError('Compairison not implemented')\n",
    "        finally:\n",
    "            global flags\n",
    "            flags = 0\n",
    "            if not result:\n",
    "                for i, test in enumerate(results):\n",
    "                    if not test:\n",
    "                        match i:\n",
    "                            case 0:\n",
    "                                flags = flags | Bitflag.PRES\n",
    "                            case 1:\n",
    "                                flags = flags | Bitflag.TEMP\n",
    "                            case 2:\n",
    "                                flags = flags | Bitflag.DEWP\n",
    "                            case 3:\n",
    "                                flags = flags | Bitflag.U\n",
    "                            case 4:\n",
    "                                flags = flags | Bitflag.V\n",
    "                            case _:\n",
    "                                raise RuntimeError(f'Invalid flag set: {i}')\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Satelite (Sat) class*\n",
    "\n",
    "This class is used to set the attributes for any data objects that cares about satelite data. This is usually the WRF data or TROPOMI or OCO-2 data. It inherits from the base class. **Note**: The respective classes for TROPOMI and OCO-2 are still in development (9-9-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sat_point(Base_point):\n",
    "    def __init__(self, loc: str, **kwargs) -> None:\n",
    "        super().__init__(loc, **kwargs)\n",
    "    def sat_loc(self, ulat: float, ulon: float, lats: c.Iterable[float], lons: c.Iterable[float]) -> tuple[int, int] | int:\n",
    "        R: int = 6371000\n",
    "        lat1: npt.NDArray[np.float32] | float = np.radians(ulat)\n",
    "        lat2: npt.NDArray[np.float32] = np.radians(lats)\n",
    "        delta_lat: npt.NDArray[np.float32] = np.radians(lats-ulat)\n",
    "        delta_lon: npt.NDArray[np.float32] = np.radians(lons-ulon)\n",
    "        a: npt.NDArray[np.float32] = (np.sin(delta_lat/2))*(np.sin(delta_lat/2))+(np.cos(lat1))*(np.cos(lat2))*(np.sin(delta_lon/2))*(np.sin(delta_lon/2))\n",
    "        c: npt.NDArray[np.float32] = 2*np.arctan2(np.sqrt(a),np.sqrt(1-a))\n",
    "        d: npt.NDArray[np.float32] = R*c\n",
    "        if d.ndim == 1:\n",
    "            return d.argmin()\n",
    "        else:\n",
    "            x: int = 0\n",
    "            y: int = 0\n",
    "            x, y = unravel_index(d.argmin(),d.shape)\n",
    "            return x,y\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        result: bool | None = None\n",
    "        try:\n",
    "            if isinstance(self, Tropomi_point) or (isinstance(self, WRF_point) and isinstance(other, Tropomi_point)):\n",
    "                results: npt.NDArray[np.bool_] = np.empty(2, np.bool_)\n",
    "                results[0] = self._rmse(self.xch4, other.xch4) <= 1.e-1\n",
    "                results[1] = self._rmse(self.xco, other.xco) <= 1.e-1\n",
    "                result = bool(results.all())\n",
    "            #! elif for OCO-2 here\n",
    "        except AttributeError:\n",
    "            if isinstance(self, WRF_point):\n",
    "                result = other.__eq__(self)\n",
    "            else:\n",
    "                raise NotImplementedError('Compairison not implemented')\n",
    "        else:\n",
    "            if result is None:\n",
    "                if isinstance(self,WRF_point):\n",
    "                    result = other.__eq__(self)\n",
    "                else:\n",
    "                    raise NotImplementedError('Compairison not implemented')\n",
    "            else:\n",
    "                pass\n",
    "        finally:\n",
    "            global flags\n",
    "            flags = 0\n",
    "            if not result:\n",
    "                for i, test in enumerate(results):\n",
    "                    if not test:\n",
    "                        if isinstance(self, Tropomi_point) or (isinstance(self, WRF_point) and isinstance(other, Tropomi_point)): \n",
    "                            match i:\n",
    "                                case 0:\n",
    "                                    flags = flags | Bitflag.XCH4\n",
    "                                case 1:\n",
    "                                    flags = flags | Bitflag.XCO\n",
    "                                case _:\n",
    "                                    raise RuntimeError(f'Invalid flag set: {i}')\n",
    "                        else:\n",
    "                            match i:\n",
    "                                case 0:\n",
    "                                    flags = flags | Bitflag.XCO2\n",
    "                                case _:\n",
    "                                    raise RuntimeError(f'Invalid flag set: {i}')\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Surface class*\n",
    "\n",
    "This class is used to set the attirbutes for any data object that cares about surface data. This is usually the WRF data or the ASOS observation data. It inherits from the base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Surface_point(Base_point):\n",
    "    def __init__(self, loc: str, **kwargs) -> None:\n",
    "        super().__init__(loc, **kwargs)\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        global flags\n",
    "        if isinstance(self, Obs_point) and self.met:\n",
    "            try:\n",
    "                results: npt.NDArray[np.bool_] = np.empty(5, np.bool_)\n",
    "                results[0] = self._rmse(self.T2, other.T2) <= 5. * units.kelvin\n",
    "                results[1] = self._rmse(self.td2, other.td2) <= 5. * units.kelvin\n",
    "                results[2] = self._rmse(self.slp, other.slp) <= 2.0 * units.hPa\n",
    "                results[3] = self._rmse(self.u10, other.u10) <= 2.24 * units('m/s')\n",
    "                results[4] = self._rmse(self.v10, other.v10) <= 2.24 * units('m/s')\n",
    "                result: bool = bool(results.all())\n",
    "            except AttributeError:\n",
    "                if isinstance(self, WRF_point):\n",
    "                    result: bool = other.__eq__(self)\n",
    "                else:\n",
    "                    raise NotImplementedError('Comparison not implemented')\n",
    "            finally:\n",
    "                flags = 0\n",
    "                if not result:\n",
    "                    for i, test in enumerate(results):\n",
    "                        if not test:\n",
    "                            match i:\n",
    "                                case 0:\n",
    "                                    flags = flags | Bitflag.T2\n",
    "                                case 1:\n",
    "                                    flags = flags | Bitflag.TD2\n",
    "                                case 2:\n",
    "                                    flags = flags | Bitflag.SLP\n",
    "                                case 3:\n",
    "                                    flags = flags | Bitflag.U10\n",
    "                                case 4:\n",
    "                                    flags = flags | Bitflag.V10\n",
    "                                case _:\n",
    "                                    raise RuntimeError(f'Invalid flag set: {i}')\n",
    "                return result\n",
    "        if isinstance(self, Obs_point) and self.chem:\n",
    "            try:\n",
    "                results: npt.NDArray[np.bool_] = np.empty(2, np.bool_)\n",
    "                results[0] = self._rmse(self.ch4, other.ch4[:,0]) <= 10. * units.ppb\n",
    "                results[1] = self._rmse(self.co2, other.co2[:,0]) <= 10. * units.ppm #! Check values!!!\n",
    "                #results[2] = self._rmse(self.xco, other.xco) <= 100. * units.ppb\n",
    "                result: bool = bool(results.all())\n",
    "            except AttributeError:\n",
    "                if isinstance(self, WRF_point):\n",
    "                    result: bool = other.__eq__(self)\n",
    "                else:\n",
    "                    raise NotImplementedError('Comparison not implemented')\n",
    "            finally:\n",
    "                flags = 0\n",
    "                if not result:\n",
    "                    for i, test in enumerate(results):\n",
    "                        if not test:\n",
    "                            match i:\n",
    "                                case 0:\n",
    "                                    flags = flags | Bitflag.XCH4\n",
    "                                case 1:\n",
    "                                    flags = flags | Bitflag.XCO2\n",
    "                                #case 2:\n",
    "                                 #   flags = flags | Bitflag.XCO\n",
    "                                case _:\n",
    "                                    raise RuntimeError(f'Invalid flag set: {i}')\n",
    "                return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *WRF class*\n",
    "\n",
    "This class ingests the wrfout data that you need to run the validation suite. Since it's what we're testing, it inherits from UA, Sat, and Surface classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRF_point(Surface_point,Sat_point,UA_point):\n",
    "    '''\n",
    "    WRF_point: sets up validation point using WRF data. Reads T2, TD2, SLP, and 10m Wind speed/direction. Inherits from Base_point.\n",
    "    '''\n",
    "    def __init__(self, wrffile: Dataset, lat: float, lon: float, loc: str, chem: bool | None = None, **kwargs) -> None:\n",
    "        super().__init__(loc,**kwargs)\n",
    "        wrf.omp_set_num_threads(wrf.omp_get_num_procs())\n",
    "        self.lat: float = lat\n",
    "        self.lon: float = lon\n",
    "        self.x: float | npt.NDArray | DataArray\n",
    "        self.y: float | npt.NDArray | DataArray\n",
    "        self.x, self.y = wrf.ll_to_xy(wrffile,self.lat,self.lon)\n",
    "        self.vars: list[str] = ['T2', 'td2', 'slp','uvmet10','p','temp','td','uvmet']\n",
    "        for var in self.vars:\n",
    "            if var == 'T2':\n",
    "                try:\n",
    "                    self.T2: DataArray = wrf.getvar(wrffile, var, wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    self.T2: DataArray = self.memory_loop(wrffile, var)\n",
    "            elif var == 'td2':\n",
    "                try:\n",
    "                    self.td2: DataArray = wrf.getvar(wrffile, var, wrf.ALL_TIMES, units='K')[..., self.y, self.x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    self.td2: DataArray = wrf._memory_loop(wrffile, var, 'K')\n",
    "            elif var == 'slp':\n",
    "                try:\n",
    "                    self.slp: DataArray = wrf.getvar(wrffile, var, wrf.ALL_TIMES, units='hPa')[..., self.y, self.x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    self.slp: DataArray = self._memory_loop(wrffile, var, 'hPa')\n",
    "            elif var == 'uvmet10':\n",
    "                try:\n",
    "                    self.u10, self.v10 = wrf.getvar(wrffile, var, wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify() #type: tuple[DataArray, DataArray]\n",
    "                except MemoryError:\n",
    "                    self.u10, self.v10 = self._memory_loop(wrffile, var) #type: tuple[DataArray, DataArray]\n",
    "            elif var == 'p':\n",
    "                try:\n",
    "                    self.p: DataArray = wrf.getvar(wrffile, var, wrf.ALL_TIMES, units='hPa')[..., self.y, self.x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    self.p: DataArray = self._memory_loop(wrffile, var, 'hPa')\n",
    "            elif var == 'temp':\n",
    "                try:\n",
    "                    self.t: DataArray = wrf.getvar(wrffile, var, wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    self.t: DataArray = self._memory_loop(wrffile, var)\n",
    "            elif var == 'td':\n",
    "                try:\n",
    "                    self.td: DataArray = wrf.getvar(wrffile, var, wrf.ALL_TIMES, units='K')[..., self.y, self.x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    self.td: DataArray = self._memory_loop(wrffile, var, 'K')\n",
    "            elif var == 'uvmet':\n",
    "                try:\n",
    "                    self.u, self.v = wrf.getvar(wrffile, var, wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify() #type: tuple[DataArray, DataArray]\n",
    "                except MemoryError:\n",
    "                    self.u, self.v = self._memory_loop(wrffile, var) #type: tuple[DataArray, DataArray]\n",
    "        ## ! Next if/elif block needs to be edited depending on WRF-GHG output structure (include converting units) ! ## \n",
    "        try:\n",
    "            self.sfc_pres: DataArray = wrf.getvar(wrffile, 'PSFC',wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify() #! may need to calculate or may be in WRF output\n",
    "        except MemoryError:\n",
    "            self.sfc_pres: DataArray = self._memory_loop(wrffile, 'PSFC') #! may need to calculate or may be in WRF output\n",
    "        if chem:\n",
    "            self.xch4: npt.ArrayLike = self._extract_ghg(wrffile, 'xch4', lat=lat, lon=lon, loc=loc)\n",
    "           # self.xco: npt.ArrayLike = self._extract_ghg(wrffile, 'xco')\n",
    "            self.xco2: npt.ArrayLike = self._extract_ghg(wrffile, 'xco2', lat=lat, lon=lon, loc=loc)\n",
    "            ch4_ant = wrf.getvar(wrffile, 'CH4_ANT', wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "            ch4_bio = wrf.getvar(wrffile, 'CH4_BIO', wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "            ch4_bck = wrf.getvar(wrffile, 'CH4_BCK', wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "            self.ch4 = ch4_ant + ch4_bio - ch4_bck\n",
    "            co2_ant = wrf.getvar(wrffile, 'CO2_ANT', wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "            co2_bio = wrf.getvar(wrffile, 'CO2_BIO', wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "            co2_bck = wrf.getvar(wrffile, 'CO2_BCK', wrf.ALL_TIMES)[..., self.y, self.x].metpy.quantify()\n",
    "            self.co2 = co2_ant + co2_bio - co2_bck\n",
    "    @staticmethod\n",
    "    def _extract_ghg(wrffile: Dataset, chem: str,*,lat=None,lon=None,loc=None) -> npt.ArrayLike:\n",
    "        try:\n",
    "            p = self.p\n",
    "            x = self.x\n",
    "            y = self.y\n",
    "            sfc_pres = self.sfc_pres\n",
    "        except NameError:\n",
    "            assert lat\n",
    "            assert lon\n",
    "            assert loc\n",
    "            data = WRF_point(wrffile,lat,lon,loc)\n",
    "            p = data.p\n",
    "            x = data.x\n",
    "            y = data.y\n",
    "            sfc_pres = data.sfc_pres\n",
    "            del data\n",
    "        if chem == 'xch4':\n",
    "            _ant: DataArray = wrf.getvar(wrffile, 'CH4_ANT', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "            _bck: DataArray = wrf.getvar(wrffile, 'CH4_BCK', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "            _tst: DataArray = wrf.getvar(wrffile, 'CH4_BIO', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "        elif chem == 'xco2':\n",
    "            _ant: DataArray = wrf.getvar(wrffile, 'CO2_ANT', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "            _bck: DataArray = wrf.getvar(wrffile, 'CO2_BCK', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "            _tst: DataArray = wrf.getvar(wrffile, 'CO2_BIO', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "        #elif chem == 'xco':\n",
    "         #   _ant: DataArray = wrf.getvar(wrffile, 'CO_ANT', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "          #  _bck: DataArray = wrf.getvar(wrffile, 'CO_BCK', wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "            #_tst = wrffile['CO_BIO'][0, :, y, x] ##?\n",
    "           # _tst: npt.NDArray = np.zeros_like(_bck)\n",
    "        _ghg = _tst + _ant -_bck\n",
    "        if ((len(_ghg) == len(p)) and (_ghg.ndim == 1)):\n",
    "            pres_bound: DataArray = xr.DataArray(np.empty_like(p), p.coords, p.dims)\n",
    "            for i, pres in enumerate(p):\n",
    "                if i == 0:\n",
    "                    pres_bound[i] = sfc_pres\n",
    "                    pres_bound[i+1] = pres_bound[i] + (2*(pres-pres_bound[i]))\n",
    "                else:\n",
    "                    try:\n",
    "                        pres_bound[i+1] = pres_bound[i] + (2*(pres-pres_bound[i]))\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            p_layer_diff: npt.NDArray = np.array([pres_bound[i]-pres_bound[i-1] for i in range(1,len(pres_bound))]) #! This may need a value at beginning for xch4[0]\n",
    "            p_diff: float = pres_bound[0] - pres_bound[-1]\n",
    "            return (np.sum(_ghg*p_layer_diff)/p_diff)\n",
    "        elif ((len(_ghg[0,:]) == len(p[0,:])) and (_ghg.ndim == 2)):\n",
    "            pres_bound: DataArray = xr.DataArray(np.empty_like(p), p.coords, p.dims) *units.hPa\n",
    "            pres_bound[:,0] = sfc_pres\n",
    "            for j in range(p.shape[0]):\n",
    "                for i, pres in enumerate(p[j,:]):\n",
    "                    try:\n",
    "                        pres_bound[j,i+1] = pres_bound[j,i] + (2*(pres-pres_bound[j,i]))\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            p_layer_diff = xr.DataArray([pres_bound[:,i-1]-pres_bound[:,i] for i in range(1,pres_bound.shape[1])],coords=p.T.coords) * units.hPa\n",
    "            p_layer_diff = np.insert(p_layer_diff,[0], sfc_pres-p[:,0],axis=0).T * units.hPa#! This may need a value at beginning for xch4[0]\n",
    "            p_diff = pres_bound[:,0] - pres_bound[:,-1]\n",
    "            return (np.sum(_ghg*p_layer_diff,axis=1)/p_diff)\n",
    "    @staticmethod\n",
    "    def _memory_loop(wrffile, var, x=None, y=None, units=None):\n",
    "        length = len(wrffile)\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "        if length % 24 == 0:\n",
    "            loops = length // 24\n",
    "            if loops == 1:\n",
    "                loops = 3\n",
    "            elif loops == 24:\n",
    "                loops = 48\n",
    "            loop_seg = length // loops\n",
    "            if var not in ['uvmet10','uvmet']:\n",
    "                var_array = []\n",
    "                for n in range(0,loops):\n",
    "                    if units is not None:\n",
    "                        var_array.append(wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES,units=units)[...,y,x].metpy.quantify())\n",
    "                    else:\n",
    "                        var_array.append(wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify())\n",
    "                return xr.concat(var_array, dims='Time')\n",
    "            else:\n",
    "                u_array = []\n",
    "                v_array = []\n",
    "                for n in range(0,loops):\n",
    "                    if units is not None:\n",
    "                        u_temp, v_temp = wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify()\n",
    "                    else:\n",
    "                        u_temp, v_temp = wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify()\n",
    "                    u_array.append(u_temp)\n",
    "                    v_array.append(v_vemp)\n",
    "                    del u_temp, v_temp\n",
    "                return xr.concat(u_array, dims='Time'), xr.concat(v_array, dims='Time')\n",
    "        elif (length - 1) % 24 == 0:\n",
    "            loops = (length-1) // 24\n",
    "            if loops == 1:\n",
    "                loops = 3\n",
    "            elif loops == 24:\n",
    "                loops = 48\n",
    "            loop_seg = (length-1) // loops\n",
    "            if var not in ['uvmet10','uvmet']:\n",
    "                var_array = []\n",
    "                for n in range(0,loops):\n",
    "                    if units is not None:\n",
    "                        var_array.append(wrf.getvar(wrffile[(n*loop_seg):((n+1)*loop_seg)],var,wrf.ALL_TIMES,units=units)[...,y,x].metpy.quantify())\n",
    "                    else:\n",
    "                        var_array.append(wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify())\n",
    "                if units is not None:\n",
    "                    var_array.append(wrf.getvar(wrffile[loops*loop_seg:],var,wrf.ALL_TIMES,units=units)[...,y,x].metpy.quantify())\n",
    "                else:\n",
    "                    var_array.append(wrf.getvar(wrffile[loops*loop_seg:],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify())\n",
    "                return xr.concat(var_array, dims='Time')\n",
    "            else:\n",
    "                u_array = []\n",
    "                v_array = []\n",
    "                for n in range(0,loops):\n",
    "                    if units is not None:\n",
    "                        u_temp, v_temp = wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify()\n",
    "                    else:\n",
    "                        u_temp, v_temp = wrf.getvar(wrffile[n*loop_seg:(n+1)*loop_seg],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify()\n",
    "                    u_array.append(u_temp)\n",
    "                    v_array.append(v_vemp)\n",
    "                    del u_temp, v_temp\n",
    "                if units is not None:\n",
    "                    u_temp, v_temp = wrf.getvar(wrffile[loops*loop_seg:],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify()\n",
    "                else:\n",
    "                    u_temp, v_temp = wrf.getvar(wrffile[loops*loop_seg:],var,wrf.ALL_TIMES)[...,y,x].metpy.quantify()\n",
    "                u_array.append(u_temp)\n",
    "                v_array.append(v_vemp)\n",
    "                del u_temp, v_temp\n",
    "                return xr.concat(u_array, dims='Time'), xr.concat(v_array, dims='Time')\n",
    "        else:\n",
    "            raise RuntimeError(f'loop length not defined ({length = })')\n",
    "    def __str__(self) -> str:\n",
    "        return f'{self.loc} WRF Point has a temperature of {self.T2} K, a dewpoint of {self.td2} K, a slp of {self.slp} hPa, and the wind is {self.wspd10} m s^-1 at {self.wdir10} degrees.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Obs_point Class*\n",
    "\n",
    "This class ingests surface observation data from ASOS stations to test against WRF data. This inherits from Surface point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obs_point(Surface_point):\n",
    "    '''\n",
    "    Obs_point: sets up validation point for observation. Reads T2, TD2, slp, and wind speed/direction from ASOS data. Inherits from Base_point.\n",
    "    '''\n",
    "    def __init__(self, loc: str, obsfile: str, obstime: dt | list[dt], *, met=True, chem=False, **kwargs) -> None:\n",
    "        super().__init__(loc, **kwargs)\n",
    "        self.met = met\n",
    "        self.chem = chem\n",
    "        utc = pytz.utc\n",
    "        if isinstance(obstime, list):\n",
    "            obstime = [utc.localize(date) for date in obstime]\n",
    "        else:\n",
    "            obstime = utc.localize(obstime) \n",
    "        if self.met:\n",
    "            data: pd.DataFrame = pd.read_csv(obsfile,na_values='M',parse_dates=['valid'],date_format='%Y-%m-%d %H:%M')\n",
    "            data.valid = pd.to_datetime(data.valid).dt.tz_localize(utc)\n",
    "            if loc in ['JFK Airport','JFK','NYC/JFK', 'LaGuardia Airport', 'LGA', 'NYC/LGA', 'Central Park','NYC']:\n",
    "                delta = 540\n",
    "            else:\n",
    "                delta = 420\n",
    "            idx = []\n",
    "            if not isinstance(obstime, list):\n",
    "                for i, obs in enumerate(data.valid):\n",
    "                    if abs(obs.timestamp() - obstime.timestamp()) == delta:\n",
    "                        idx.append(i)\n",
    "                        break\n",
    "            else:\n",
    "                for time in obstime:\n",
    "                    for i, obs in enumerate(data.valid):\n",
    "                        if abs(obs.timestamp() - time.timestamp()) == delta:\n",
    "                            idx.append(i)\n",
    "                            break\n",
    "            #print(idx)\n",
    "            if isinstance(obstime,list):\n",
    "                obstime = [date.replace(tzinfo=None) for date in obstime]\n",
    "            else:\n",
    "                obstime = obstime.replace(tzinfo=None)\n",
    "            ds = Dataset.from_dataframe(data.iloc[idx])\n",
    "            ds = ds.rename({'index':'Time'}).assign_coords({'Time':obstime})\n",
    "            del data\n",
    "            self.T2: DataArray = (ds.tmpc * units.degC).metpy.convert_to_base_units()\n",
    "            self.td2: DataArray = (ds.dwpc * units.degC).metpy.convert_to_base_units()\n",
    "            self.slp: DataArray = ds.mslp * units.hPa\n",
    "            self.u10, self.v10 = wind_components((ds.sped * 0.44704) * units('m/s'), ds.drct * units.deg)\n",
    "            del ds\n",
    "        if self.chem:\n",
    "            cols = ['UTC_time','CH4_ppb','CO2_ppm']\n",
    "            data = pd.read_csv(obsfile, na_values='NA', skiprows=6, usecols=cols,parse_dates=['UTC_time'],date_format='%Y-%m-%d %H:%M')\n",
    "            data.UTC_time = pd.to_datetime(data.UTC_time).dt.tz_localize(utc)\n",
    "            idx = []\n",
    "            if not isinstance(obstime, list):\n",
    "                for i, obs in enumerate(data.UTC_time):\n",
    "                    if obs.timestamp() == obstime.timestamp():\n",
    "                        idx.append(i)\n",
    "                        break\n",
    "            else:\n",
    "                for time in obstime:\n",
    "                    for i, obs in enumerate(data.UTC_time):\n",
    "                        if obs.timestamp() == time.timestamp():\n",
    "                            idx.append(i)\n",
    "                            break\n",
    "            #print(idx)\n",
    "            if isinstance(obstime,list):\n",
    "                obstime = [date.replace(tzinfo=None) for date in obstime]\n",
    "            else:\n",
    "                obstime = obstime.replace(tzinfo=None)\n",
    "            ds = Dataset.from_dataframe(data.iloc[idx])\n",
    "            ds = ds.rename({'index':'Time'}).assign_coords({'Time':obstime})\n",
    "            del data\n",
    "            self.ch4 = (ds.CH4_ppb * units.ppb).metpy.convert_units('ppm')\n",
    "            self.co2 = ds.CO2_ppm * units.ppm\n",
    "            #self.xco = (ds.CO_ppb * units.ppb).metpy.convert_units('ppm')\n",
    "            del ds\n",
    "    def __str__(self) -> str:\n",
    "        return f'{self.loc} Observation Point has a temperature of {self.T2} K, a dewpoint of {self.td2} K, a slp of {self.slp} hPa, and the wind is {self.wspd10} m s^-1 at {self.wdir10} degrees.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *UObs_point Class*\n",
    "\n",
    "This class ingest sounding data to test against WRF data. This inherits from UA point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UObs_point(UA_point):\n",
    "    def __init__(self, loc: str, ua_file: str, wrffile: netCDF4._netCDF4.Dataset, lat: float, lon: float, **kwargs) -> None:\n",
    "        super().__init__(loc, **kwargs)\n",
    "        x, y = wrf.ll_to_xy(wrffile, lat, lon)#type: tuple(float, float)\n",
    "        wrf_p: DataArray = wrf.getvar(wrffile, 'p', units='hPa')[:, y, x]\n",
    "        data: pd.DataFrame = pd.read_csv(ua_file, na_values='M', parse_dates=['validUTC'], date_format='%Y-%m-%d %H:%M')\n",
    "        p: npt.NDArray = data.pressure_mb.to_numpy()\n",
    "        idx: npt.NDArray = np.digitize(wrf_p, p)\n",
    "        data = data.iloc[idx]\n",
    "        self.p: npt.NDArray = data.pressure_mb.to_numpy() #* mb == hPa\n",
    "        self.t: npt.NDArray = data.tmpc.to_numpy() + 273.15 #* deg C -> K\n",
    "        self.td: npt.NDArray = data.dwpc.to_numpy() + 273.15 #* deg C -> K\n",
    "        self.wdir: npt.NDArray = data.drct.to_numpy() #* deg\n",
    "        self.wspd: npt.NDArray = data.speed_kts.to_numpy() * 0.514444 #* kt -> m s^-1\n",
    "        del data, p, idx, wrf_p, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Tropomi_point class*\n",
    "\n",
    "This class ingests TROPOMI satelite data to test against WRF data. This inherits from Sat point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tropomi_point(Sat_point): #! Find some way to do both xch4 and xco, will probably need two files\n",
    "    def __init__(self, loc: str, xch4_f: str, xco_f: str, ulat: float, ulon: float, **kwargs) -> None:\n",
    "        super().__init__(loc, **kwargs)\n",
    "        self.xch4: float = self._ghg(xch4_f, 'xch4', ulat, ulon) \n",
    "        self.xco: float = self._ghg(xco_f, 'xco', ulat, ulon)\n",
    "    def _ghg(self, tropomi_f: str, chem: str, ulat: float, ulon: float) -> float:\n",
    "        ds: netCDF4._netCDF4.Dataset = Dataset(tropomi_f, 'r')\n",
    "        grp: str = 'PRODUCT'\n",
    "        if chem in ['ch4','CH4','xch4','XCH4','methane','Methane','METHANE']: #!! find a way to do both\n",
    "            self.xch4_sds = sds = 'methane_mixing_ratio' \n",
    "            self.xch4_unit: str = 'ppb'\n",
    "        elif chem in ['co','CO','xco','XCO','carbon monoxide','Carbon Monoxide', 'CARBON MONOXIDE']:\n",
    "            self.xco_sds = sds = 'carbonmonoxide_total_column_corrected' # ! is this right?\n",
    "            self.xco_unit: str = 'ppb' # * will have to convert for co\n",
    "        lats: netCDF4._netCDF4.Variable = ds.groups[grp].variables['latitude'][0][:][:]\n",
    "        lons: netCDF4._netCDF4.Variable = ds.groups[grp].variables['longitude'][0][:][:]\n",
    "        qas: npt.NDArray = np.array(ds.groups[grp].variables['qa_value'][0][:][:])\n",
    "        data: netCDF4._netCDF4.Variable = ds.groups[grp].variables[sds] #units: ppb (ch4) mol m^-2 --> ppb (co)\n",
    "        fv: float | netCDF4._netCDF4.Variable = data._FillValue\n",
    "        dA: npt.NDArray = np.array(data[0][:][:])\n",
    "        dA[(dA==fv) & (qas<=0.5)] = np.nan #? Do I want to filter for qa here or later?\n",
    "        if chem in ['co','CO','xco','XCO','carbon monoxide','Carbon Monoxide', 'CARBON MONOXIDE']:\n",
    "            dA = dA * 28.01 * 0.0001 * 1000 # converts (mol m^-2) * (g mol^-1) * (m^-1) == g m^-3 == ppm --> ppb\n",
    "        #TODO: check about averging kernel\n",
    "        min_lat: float | npt.NDArray = np.min(lats)\n",
    "        max_lat: float | npt.NDArray = np.max(lats)\n",
    "        min_lon: float | npt.NDArray = np.min(lons)\n",
    "        max_lon: float | npt.NDArray = np.max(lons)\n",
    "        if not min_lat <= ulat <= max_lat:\n",
    "            raise RuntimeError(f'User Latitude is not within TROPOMI file. {ulat}, {min_lat}, {max_lat}')\n",
    "        if not min_lon <= ulon <= max_lon:\n",
    "            raise RuntimeError(f'User Longitude is not within TROPOMI file. {ulon}, {min_lon}, {max_lon}')\n",
    "        x, y = self.sat_loc(ulat, ulon, lats, lons) #type: tuple[int, int]\n",
    "        if np.isnan(dA[x,y]): #? qa check here?\n",
    "            raise RuntimeError('No valid value at desired location.')\n",
    "        if x < 1:\n",
    "            x += 1\n",
    "        if x > dA.shape[0]-2:\n",
    "            x -= 2\n",
    "        if y < 1:\n",
    "            y += 1\n",
    "        if y > dA.shape[1]-2:\n",
    "            y -= 2\n",
    "        t_b_t: npt.NDArray = dA[x-1:x+2,y-1:y+2].astype(float)\n",
    "        # ? is this necessary? t_b_t[t_b_t==float(fv)] = np.nan\n",
    "        nnan: int = np.count_nonzero(~np.isnan(t_b_t))\n",
    "        if nnan == 0:\n",
    "            raise RuntimeError('No valid pixels in 3x3 grid.')\n",
    "        grid_avg: float = np.nanmean(t_b_t)\n",
    "        grid_std: float = np.nanstd(t_b_t)\n",
    "        if np.abs(grid_avg-dA[x,y]) <= grid_std:\n",
    "             return grid_avg\n",
    "        else:\n",
    "             return dA[x,y]\n",
    "    def __str__(self) -> str:\n",
    "        return f'TROPOMI Satelite products at {self.loc} are {self.xch4:.2e} {self.xch4_unit} of CH4 and {self.xco:.2e} {self.xco_unit} of CO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *OCO_point Class*\n",
    "\n",
    "This class ingests OCO-2/3 satelite data to compare against WRF data. This inherits from Sat_point. **NB:** Not finished yet (10/24/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCO_Point(Sat_point):\n",
    "    def __init__(self, loc, oco_f, ulat, ulon, **kwargs):\n",
    "        super().__init__(loc, **kwargs)\n",
    "        ds = Dataset(oco_f, 'r')\n",
    "        lats = ds['latitude'][:]\n",
    "        lons = ds['longitude'][:]\n",
    "        idx = self.sat_loc(ulat, ulon, lats, lons)\n",
    "        _xco2 = ds['']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Helper Functions*\n",
    "\n",
    "These functions help illustrate a pass or fail of the testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gprint(x: str) -> None: return cprint(x, 'white', 'on_green', attrs=['bold'],end=' ')\n",
    "def rprint(x: str) -> None: return cprint(x, 'white', 'on_red', attrs=['blink','bold'], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Common Setup*\n",
    "\n",
    "These options are used for each or most of the plots below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = [*range(0,24)]\n",
    "golden = (1. + np.sqrt(5.))/2.\n",
    "figsize = (12., 12./golden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Meteorological Setup*\n",
    "\n",
    "Adds the lats, lons and locations for the validation in question. Also sets up the observation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = [40.64, 40.78, 40.78]\n",
    "lons = [-73.78, -73.87, -73.97]\n",
    "days = [*(x for x in range(20,32)), *(x for x in range(1,13))]\n",
    "mons = [*([7] * 12), *([8] * 12)]\n",
    "locs = ['JFK Airport', 'LaGuardia Airport', 'Central Park']\n",
    "obs_files = ['./sfc/JFK.csv','./sfc/LGA.csv','./sfc/NYC.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Meteorological Daily Validation*\n",
    "\n",
    "This cell loops over the simulation and plots the daily time series. It also checks the RMSE for that day's worth of data against the observation and spits out a validation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_title = ['Temperature','Dew Point','Sea Level Pressure','U10 Wind Component','V10 Wind Component']\n",
    "var_limit = [5., 5., 2., 2.24, 2.24]\n",
    "var_units = ['K', 'K', 'hPa', 'm/s', 'm/s']\n",
    "var_short = ['t2','td2','slp','u10','v10']\n",
    "#print('before for loop')\n",
    "for lat, lon, loc, obs_files in zip(lats, lons, locs, obs_files):\n",
    "    t2_rmses = []\n",
    "    td2_rmses = []\n",
    "    slp_rmses = []\n",
    "    u10_rmses = []\n",
    "    v10_rmses = []\n",
    "    t2_mbias = []\n",
    "    td2_mbias = []\n",
    "    slp_mbias = []\n",
    "    u10_mbias = []\n",
    "    v10_mbias = []\n",
    "    print(f'{loc = }')\n",
    "    for month, day in zip(mons, days):\n",
    "        wrf_files = [f'./wrfout/{f}' for f in os.listdir('./wrfout') if f.startswith(f'wrfout_d02_2023-{month:02}-{day:02}')]\n",
    "        wrf_files.sort()\n",
    "        data_sets = [Ds(wrf_f) for wrf_f in wrf_files]\n",
    "        obs_dates = [dt(2023, month, day, h, 0, 0) for h in range(0,24)]\n",
    "        wrf_data = WRF_point(data_sets, lat, lon, loc)\n",
    "        obs_data = Obs_point(loc, obs_file, obs_dates)\n",
    "        #print('after data load')\n",
    "        u10_rmses.append(wrf_data._rmse(wrf_data.u10, obs_data.u10))\n",
    "        v10_rmses.append(wrf_data._rmse(wrf_data.v10, obs_data.v10))\n",
    "        slp_rmses.append(wrf_data._rmse(wrf_data.slp, obs_data.slp))\n",
    "        td2_rmses.append(wrf_data._rmse(wrf_data.td2, obs_data.td2))\n",
    "        t2_rmses.append(wrf_data._rmse(wrf_data.T2, obs_data.T2))\n",
    "        u10_mbias.append(wrf_data._mean_bias(wrf_data.u10, obs_data.u10))\n",
    "        v10_mbias.append(wrf_data._mean_bias(wrf_data.v10, obs_data.v10))\n",
    "        slp_mbias.append(wrf_data._mean_bias(wrf_data.slp, obs_data.slp))\n",
    "        td2_mbias.append(wrf_data._mean_bias(wrf_data.td2, obs_data.td2))\n",
    "        t2_mbias.append(wrf_data._mean_bias(wrf_data.T2, obs_data.T2))\n",
    "        validate = obs_data == wrf_data\n",
    "        if not validate:\n",
    "            print(f'Failed validation: {repr(flags)}')\n",
    "        else:\n",
    "            print(f'Validation passed! {repr(flags)}')\n",
    "        wrf_var_list = [wrf_data.T2, wrf_data.td2, wrf_data.slp, wrf_data.u10, wrf_data.v10]\n",
    "        obs_var_list = [obs_data.T2, obs_data.td2, obs_data.slp, obs_data.u10, obs_data.v10]\n",
    "        for wrf_var, obs_var, title, limit, unit, short in zip(wrf_var_list, obs_var_list, var_title, var_limit, var_units, var_short):\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=figsize)\n",
    "            fig.suptitle(f'Time series of {title} at {loc} for {month:02}-{day:02}-2023')\n",
    "            ax1.set_title('Values')\n",
    "            ax2.set_title('Bias')\n",
    "            ax1.plot(obs_dates, obs_var, 'k', label='Observed')\n",
    "            ax1.fill_between(obs_dates, obs_var.metpy.dequantify()-limit, obs_var.metpy.dequantify()+limit, color='b', alpha=.5)\n",
    "            ax1.plot(obs_dates, wrf_var, 'r', label='WRF Model')\n",
    "            ax1.xaxis_date()\n",
    "            ax1.set(ylabel=f'{title} ({unit})', xlabel='Time (UTC)')\n",
    "            ax2.xaxis_date()\n",
    "            ax2.set(ylabel=f'{title} Bias ({unit})', xlabel='Time (UTC)')\n",
    "            ax2.plot(obs_dates, wrf_var-obs_var, 'g', label='Bias')\n",
    "            ax2.plot(obs_dates, np.zeros(len(obs_dates)), 'm--')\n",
    "            ax2.fill_between(obs_dates, -limit, limit, color='b', alpha=.5)\n",
    "            fig.legend(loc='outside lower center', ncols=3)\n",
    "            plt.savefig(f'{short}_timeseries_{loc.replace(\" \",\"\")}_2023-{month:02}-{day:02}.png')\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_title = ['Temperature','Dew Point','Sea Level Pressure',None]\n",
    "var_limit = [5., 5., 2., 2.24]\n",
    "var_units = ['K', 'K', 'hPa', 'm/s']\n",
    "var_short = ['t2','td2', 'slp', None]\n",
    "var_wrf_getvar = ['T2', 'td2', 'slp','uvmet10']\n",
    "for lat, lon, loc, obs_file in zip(lats, lons, locs, obs_files):\n",
    "    print(f'{loc = }')\n",
    "    for title, limit, unit, short, wrf_getvar in zip(var_title, var_limit, var_units, var_short, var_wrf_getvar):\n",
    "        if title is not None:\n",
    "            print(title)\n",
    "            obs_hr_means = []\n",
    "            wrf_hr_means = []\n",
    "        else:\n",
    "            print('winds')\n",
    "            obs_u10_hr_means = []\n",
    "            obs_v10_hr_means = []\n",
    "            wrf_v10_hr_means = []\n",
    "            wrf_u10_hr_means = []\n",
    "        for hr in hrs:\n",
    "            wrf_files = [f'./wrfout/{f}' for f in os.listdir('./wrfout/') if f'_{hr:02}:' in f and f.startswith('wrfout_d02')]\n",
    "            wrf_files.sort()\n",
    "            data_sets = [Ds(wrf_f) for wrf_f in wrf_files]\n",
    "            x, y = wrf.ll_to_xy(data_sets, lat, lon)\n",
    "            obs_dates = [dt(2023, month, day, hr, 0, 0) for month, day in zip(mons, days)]\n",
    "            if title is not None:\n",
    "                if title != 'Temperature':\n",
    "                    try:\n",
    "                        wrf_data = wrf.getvar(data_sets, wrf_getvar, wrf.ALL_TIMES,units=unit)[..., y, x].metpy.quantify()\n",
    "                    except MemoryError:\n",
    "                        wrf_data = WRF_point._memory_loop(data_sets, wrf_getvar, x, y, unit)\n",
    "                else:\n",
    "                    try:\n",
    "                        wrf_data = wrf.getvar(data_sets, wrf_getvar, wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "                    except MemoryError:\n",
    "                        wrf_data = WRF_point._memory_loop(data_sets, wrf_getvar, x, y)\n",
    "            else:\n",
    "                try:\n",
    "                    wrf_u10, wrf_v10 = wrf.getvar(data_sets, wrf_getvar, wrf.ALL_TIMES)[..., y, x].metpy.quantify()\n",
    "                except MemoryError:\n",
    "                    wrf_u10, wrf_v10 = WRF_point._memory_loop(data_sets, wrf_getvar, x, y)\n",
    "            obs_data = Obs_point(loc, obs_file, obs_dates)\n",
    "            match title:\n",
    "                case 'Temperature':\n",
    "                    wrf_hr_means.append(np.nanmean(wrf_data))\n",
    "                    obs_hr_means.append(np.nanmean(obs_data.T2))\n",
    "                case 'Dew Point':\n",
    "                    wrf_hr_means.append(np.nanmean(wrf_data))\n",
    "                    obs_hr_means.append(np.nanmean(obs_data.td2))\n",
    "                case 'Sea Level Pressure':\n",
    "                    wrf_hr_means.append(np.nanmean(wrf_data))\n",
    "                    obs_hr_means.append(np.nanmean(obs_data.slp))\n",
    "                case None:\n",
    "                    wrf_v10_hr_means.append(np.nanmean(wrf_v10))\n",
    "                    wrf_u10_hr_means.append(np.nanmean(wrf_u10))\n",
    "                    obs_v10_hr_means.append(np.nanmean(obs_data.v10))\n",
    "                    obs_u10_hr_means.append(np.nanmean(obs_data.u10))\n",
    "                case _:\n",
    "                    raise RuntimeError('Variable not valid')\n",
    "        if title is not None:\n",
    "            obs_var = np.array(obs_hr_means)\n",
    "            wrf_var = np.array(wrf_hr_means)\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize = figsize,sharex=True)\n",
    "            fig.suptitle(f'Mean Time Series of {title} at {loc}')\n",
    "            ax1.set_title('Values')\n",
    "            ax2.set_title('Bias')\n",
    "            ax1.plot(hrs, obs_var, 'k', label='Observed')\n",
    "            ax1.fill_between(hrs, obs_var-limit, obs_var+limit, color='b', alpha=.5)\n",
    "            ax1.plot(hrs, wrf_var, 'r', label='WRF Model')\n",
    "            #ax1.xaxis_date()\n",
    "            ax1.set(ylabel=f'{title} ({unit})', xticks=hrs)\n",
    "            #ax2.xaxis_date()\n",
    "            ax2.set(ylabel=f'{title} Bias ({unit})', xlabel='Time (UTC)', xticks=hrs)\n",
    "            ax2.plot(hrs, wrf_var-obs_var, 'g', label='Bias')\n",
    "            ax2.plot(hrs, np.zeros(len(hrs)), 'm--', label='Zero Bias')\n",
    "            ax2.fill_between(hrs, -limit, limit, color='b', alpha=.5)\n",
    "            fig.legend(loc='outside lower center', ncols=4)\n",
    "            plt.savefig(f'{short}_timeseries_{loc.replace(\" \",\"\")}_2023-average.png')\n",
    "            plt.close()\n",
    "            del obs_hr_means, wrf_hr_means, obs_var, wrf_var\n",
    "        else:\n",
    "            obs_v10 = np.array(obs_v10_hr_means)\n",
    "            wrf_v10 = np.array(wrf_v10_hr_means)\n",
    "            obs_u10 = np.array(obs_u10_hr_means)\n",
    "            wrf_u10 = np.array(wrf_u10_hr_means)\n",
    "            wind_title = ['U10 Wind Component','V10 Wind Component']\n",
    "            wind_short = ['u10', 'v10']\n",
    "            obs_wind = [obs_u10, obs_v10]\n",
    "            wrf_wind = [wrf_u10, wrf_v10]\n",
    "            for title, short, obs_var, wrf_var in zip(wind_title, wind_short, obs_wind, wrf_wind):\n",
    "                fig, (ax1, ax2) = plt.subplots(2, 1, figsize = figsize, sharex=True)\n",
    "                fig.suptitle(f'Mean Time Series of {title} at {loc}')\n",
    "                ax1.set_title('Values')\n",
    "                ax2.set_title('Bias')\n",
    "                ax1.plot(hrs, obs_var, 'k', label='Observed')\n",
    "                ax1.fill_between(hrs, obs_var-limit, obs_var+limit, color='b', alpha=.5)\n",
    "                ax1.plot(hrs, wrf_var, 'r', label='WRF Model')\n",
    "                #ax1.xaxis_date()\n",
    "                ax1.set(ylabel=f'{title} ({unit})', xticks=hrs)\n",
    "                #ax2.xaxis_date()\n",
    "                ax2.set(ylabel=f'{title} Bias ({unit})', xlabel='Time (UTC)',xticks=hrs)\n",
    "                ax2.plot(hrs, wrf_var-obs_var, 'g', label='Bias')\n",
    "                ax2.plot(hrs, np.zeros(len(hrs)), 'm--', label='Zero Bias')\n",
    "                ax2.fill_between(hrs, -limit, limit, color='b', alpha=.5)\n",
    "                fig.legend(loc='outside lower center', ncols=4)\n",
    "                plt.savefig(f'{short}_timeseries_{loc.replace(\" \",\"\")}_2023-average.png')\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = [40.64, 40.78, 40.78]\n",
    "lons = [-73.78, -73.87, -73.97]\n",
    "locs = ['Rutgers', 'LDEO', 'ASRC']\n",
    "obs_files = ['./sfc/Rutgers.txt','./sfc/LDEO.txt','./sfc/ASRC.txt']\n",
    "var_title = ['CH4 Concentration','CO2 Concentration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_limit = [10. * units.ppb, 10. * units.ppm]\n",
    "var_units = ['ppb', 'ppm']\n",
    "var_short = ['ch4','co2']\n",
    "#print('before for loop')\n",
    "for lat, lon, loc, obs_file in zip(lats, lons, locs, obs_files):\n",
    "    print(f'{loc = }')\n",
    "    for month, day in zip(mons, days):\n",
    "        wrf_files = [f'./wrfout/{f}' for f in os.listdir('./wrfout') if f.startswith(f'wrfout_d02_2023-{month:02}-{day:02}')]\n",
    "        wrf_files.sort()\n",
    "        data_sets = [Ds(wrf_f) for wrf_f in wrf_files]\n",
    "        obs_dates = [dt(2023, month, day, h, 0, 0) for h in range(0,24)]\n",
    "        wrf_data = WRF_point(data_sets, lat, lon, loc, chem=True)\n",
    "        obs_data = Obs_point(loc, obs_file, obs_dates, met=False, chem=True)\n",
    "        #print('after data load')\n",
    "        validate = obs_data == wrf_data\n",
    "        if not validate:\n",
    "            print(f'Failed validation: {repr(flags)}')\n",
    "        else:\n",
    "            print(f'Validation passed! {repr(flags)}')\n",
    "        wrf_var_list = [wrf_data.ch4[:,0], wrf_data.co2[:,0]]\n",
    "        obs_var_list = [obs_data.ch4, obs_data.co2]\n",
    "        for wrf_var, obs_var, title, limit, unit, short in zip(wrf_var_list, obs_var_list, var_title, var_limit, var_units, var_short):\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=figsize)\n",
    "            fig.suptitle(f'Time series of {title} at {loc} for {month:02}-{day:02}-2023')\n",
    "            ax1.set_title('Values')\n",
    "            ax2.set_title('Bias')\n",
    "            ax1.plot(obs_dates, obs_var.metpy.convert_units(unit), 'k', label='Observed')\n",
    "            ax1.fill_between(obs_dates, obs_var.metpy.convert_units(unit)-limit, obs_var.metpy.convert_units(unit)+limit, color='b', alpha=.5)\n",
    "            ax1.plot(obs_dates, wrf_var.metpy.convert_units(unit), 'r', label='WRF Model')\n",
    "            ax1.xaxis_date()\n",
    "            ax1.set(ylabel=f'{title} ({unit})', xlabel='Time (UTC)')\n",
    "            ax2.xaxis_date()\n",
    "            ax2.set(ylabel=f'{title} Bias ({unit})', xlabel='Time (UTC)')\n",
    "            ax2.plot(obs_dates, wrf_var.metpy.convert_units(unit)-obs_var.metpy.convert_units(unit), 'g', label='Bias')\n",
    "            ax2.plot(obs_dates, np.zeros(len(obs_dates)), 'm--')\n",
    "            ax2.fill_between(obs_dates, -limit, limit, color='b', alpha=.5)\n",
    "            fig.legend(loc='outside lower center', ncols=3)\n",
    "            plt.savefig(f'{short}_timeseries_{loc.replace(\" \",\"\")}_2023-{month:02}-{day:02}.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_wrf_getvar = ['ch4','co2']\n",
    "for lat, lon, loc, obs_file in zip(lats, lons, locs, obs_files):\n",
    "    print(f'{loc = }')\n",
    "    for title, limit, unit, short, wrf_getvar in zip(var_title, var_limit, var_units, var_short, var_wrf_getvar):\n",
    "        print(f'{title = }')\n",
    "        obs_hr_means = []\n",
    "        wrf_hr_means = []\n",
    "        for hr in hrs:\n",
    "            wrf_files = [f'./wrfout/{f}' for f in os.listdir('./wrfout/') if f'_{hr:02}:' in f and f.startswith('wrfout_d02')]\n",
    "            wrf_files.sort()\n",
    "            data_sets = [Ds(wrf_f) for wrf_f in wrf_files]\n",
    "            x, y = wrf.ll_to_xy(data_sets, lat, lon)\n",
    "            obs_dates = [dt(2023, month, day, hr, 0, 0) for month, day in zip(mons, days)]\n",
    "            wrf_data = WRF_point(data_sets, lat, lon, loc, chem=True)\n",
    "            obs_data = Obs_point(loc, obs_file, obs_dates, met=False, chem=True)\n",
    "            match title:\n",
    "                case 'CO2 Concentration':\n",
    "                    wrf_hr_means.append(wrf_data.co2[:,0].mean(skipna=True))\n",
    "                    obs_hr_means.append(obs_data.co2.mean(skipna=True))\n",
    "                case 'CH4 Concentration':\n",
    "                    wrf_hr_means.append(wrf_data.ch4[:,0].mean(skipna=True))\n",
    "                    obs_hr_means.append(obs_data.ch4.mean(skipna=True))\n",
    "                case _:\n",
    "                    raise RuntimeError('Variable not valid.')\n",
    "        obs_var = xr.DataArray(obs_hr_means) * units.ppm\n",
    "        wrf_var = xr.DataArray(wrf_hr_means) * units.ppm\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize = figsize,sharex=True)\n",
    "        fig.suptitle(f'Mean Time Series of {title} at {loc}')\n",
    "        ax1.set_title('Values')\n",
    "        ax2.set_title('Bias')\n",
    "        ax1.plot(hrs, obs_var.metpy.convert_units(unit), 'k', label='Observed')\n",
    "        ax1.fill_between(hrs, obs_var.metpy.convert_units(unit)-limit, obs_var.metpy.convert_units(unit)+limit, color='b', alpha=.5)\n",
    "        ax1.plot(hrs, wrf_var.metpy.convert_units(unit), 'r', label='WRF Model')\n",
    "        #ax1.xaxis_date()\n",
    "        ax1.set(ylabel=f'{title} ({unit})', xticks=hrs)\n",
    "        #ax2.xaxis_date()\n",
    "        ax2.set(ylabel=f'{title} Bias ({unit})', xlabel='Time (UTC)', xticks=hrs)\n",
    "        ax2.plot(hrs, wrf_var.metpy.convert_units(unit)-obs_var.metpy.convert_units(unit), 'g', label='Bias')\n",
    "        ax2.plot(hrs, np.zeros(len(hrs)), 'm--', label='Zero Bias')\n",
    "        ax2.fill_between(hrs, -limit, limit, color='b', alpha=.5)\n",
    "        fig.legend(loc='outside lower center', ncols=4)\n",
    "        plt.savefig(f'{short}_timeseries_{loc.replace(\" \",\"\")}_2023-average.png')\n",
    "        plt.close()\n",
    "        del obs_hr_means, wrf_hr_means, obs_var, wrf_var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
